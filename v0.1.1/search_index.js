var documenterSearchIndex = {"docs":
[{"location":"1_intro/#theory","page":"Theory and Notation","title":"Theory and Notation","text":"","category":"section"},{"location":"1_intro/#Hidden-Markov-models","page":"Theory and Notation","title":"Hidden Markov models","text":"","category":"section"},{"location":"1_intro/","page":"Theory and Notation","title":"Theory and Notation","text":"A hidden Markov model (HMM)  with N_s states is defined by the following parameters:","category":"page"},{"location":"1_intro/","page":"Theory and Notation","title":"Theory and Notation","text":"Initial state probability vector: mathbfa = a_1dotsa_N_s^intercal where the j-th element gives  the initial probability of being at state  s_t = j at time t=0.  Summing the elements of the vector gives 1.\nTransition matrix: mathbfA in mathbbR^N_s times N_s where the element a_ji=p(s_t=js_t-1=i)  indicates the probability of going from state s_t-1 = i to  state s_t = j. Requires to satisfy sum_j=1^N_s a_ji = 1 for all  j= 1 dots N_s i.e. the elements of the rows of mathbfA must sum to 1.\nObservation probabilities: each state j=1dotsN_s is associated  for example with a probability density function b_i(mathbfx_t),  where mathbfx_t in mathbbR^N_x is  a vector of observations at time t. For a sequence of N_t observations,  mathbfX = mathbfx_1 dots mathbfx_N_t^intercal, the operator  B_mathcalW mathbbR^N_t times N_x rightarrow mathbbR^N_t times N_s where mathcalW is a set of parameters, maps the observations to mathbfY = mathbfy_1 dots mathbfy_N_t^intercal, where the element y_tj=p(mathbfx_ts_t=j)  is the likelihood of mathbfx_t  for a given state j.","category":"page"},{"location":"1_intro/#Maximum-likelihood-(ML)","page":"Theory and Notation","title":"Maximum likelihood (ML)","text":"","category":"section"},{"location":"1_intro/","page":"Theory and Notation","title":"Theory and Notation","text":"Given the observation mathbfX, we would like to obtain a HMM  capable of describing this as sequences of states that are directly measurable. Typically a set of N_d observations  mathcalD =  mathbfX_1 dots mathbfX_N_d  is used but we consider only a single one  to simplify the notation. The optimal HMM parameters mathcalL^star =   mathbfa^star mathbfA^star mathcalW^star  can be obtained by maximizing the likelihood of the observations. This can be achieved by minimizing the  negative logarithm of this likelihood:","category":"page"},{"location":"1_intro/","page":"Theory and Notation","title":"Theory and Notation","text":"textminimize_mathcalL \n \n-log( p (mathbfX) ) = \n-log( sum_ mathbfs in mathcalN  \np ( mathbfX  mathbfs  ) p ( mathbfs ) \n)\n","category":"page"},{"location":"1_intro/","page":"Theory and Notation","title":"Theory and Notation","text":"where mathbfs in mathbbN^N_t is sequence of states,  and mathcalN is the set of  all possible state sequences. Since mathcalN has N_s^N_t elements, in general it is not feasible to compute the cost function by explicitly computing this summation. Instead, it is convenient to \"split\" p(mathbfX) at a particular time t:","category":"page"},{"location":"1_intro/","page":"Theory and Notation","title":"Theory and Notation","text":"p(mathbfX) = \nsum_i in mathcalN_tj\np(mathbfXs_t=j)","category":"page"},{"location":"1_intro/","page":"Theory and Notation","title":"Theory and Notation","text":"where mathcalN_tj are the  allowed transitions from state j at time t,","category":"page"},{"location":"1_intro/","page":"Theory and Notation","title":"Theory and Notation","text":"p(mathbfXs_t=j) = \np(mathbfx_1dotsmathbfx_ts_t=j)\np(mathbfx_t+1dotsmathbfx_N_t  mathbfx_1dotsmathbfx_ts_t=j)","category":"page"},{"location":"1_intro/","page":"Theory and Notation","title":"Theory and Notation","text":"since we are assuming observation independence,  we can drop the conditions of the second term:","category":"page"},{"location":"1_intro/","page":"Theory and Notation","title":"Theory and Notation","text":"p(mathbfx_1dotsmathbfx_ts_t=j)\np(mathbfx_t+1dotsmathbfx_N_ts_t=j  s_t=j) =\nalpha_tj beta_tj","category":"page"},{"location":"1_intro/","page":"Theory and Notation","title":"Theory and Notation","text":"where alpha_tj and beta_tj are the  forward and backward probabilities. The computation of these probabilities can be performed in  a recursive way going either forward and backward in time.","category":"page"},{"location":"1_intro/","page":"Theory and Notation","title":"Theory and Notation","text":"The forward probabilities can be written as:","category":"page"},{"location":"1_intro/","page":"Theory and Notation","title":"Theory and Notation","text":"alpha_1j = a_j y_1j\n  textfor   j =1dotsN_s","category":"page"},{"location":"1_intro/","page":"Theory and Notation","title":"Theory and Notation","text":"alpha_tj = sum_i in mathcalN_tj alpha_t-1i \na_ij y_tj \n  textfor   t = 2dotsN_t   j=1dotsN_s","category":"page"},{"location":"1_intro/","page":"Theory and Notation","title":"Theory and Notation","text":"and using matrix notation:","category":"page"},{"location":"1_intro/","page":"Theory and Notation","title":"Theory and Notation","text":"boldsymbolalpha_1 = textdiag(mathbfy_1) mathbfa","category":"page"},{"location":"1_intro/","page":"Theory and Notation","title":"Theory and Notation","text":"boldsymbolalpha_t =textdiag(mathbfy_t) mathbfA_t^intercal  boldsymbolalpha_t-1\n  textfor   t = 2dotsN_t   j=1dotsN_s","category":"page"},{"location":"1_intro/","page":"Theory and Notation","title":"Theory and Notation","text":"where boldsymbolalpha_t is a N_s-long vector containing the  forward probabilities at time t  and mathbfA_t = mathbfN_t mathbfA, where mathbfN_t is a selection matrix which includes  only the allowed indices at time t.","category":"page"},{"location":"1_intro/","page":"Theory and Notation","title":"Theory and Notation","text":"Backward probabilities:","category":"page"},{"location":"1_intro/","page":"Theory and Notation","title":"Theory and Notation","text":"beta_N_tj = 1\n  textfor    j =1dotsN_s","category":"page"},{"location":"1_intro/","page":"Theory and Notation","title":"Theory and Notation","text":"beta_tj = sum_k in barmathcalN_t+1j beta_t+1k \na_jk y_t+1k\n  textfor   t = N_t-1dots1","category":"page"},{"location":"1_intro/","page":"Theory and Notation","title":"Theory and Notation","text":"where barmathcalN_tj are the  allowed transitions arriving from state j at time t. Using matrix notation:","category":"page"},{"location":"1_intro/","page":"Theory and Notation","title":"Theory and Notation","text":"boldsymbolbeta_N_t = mathbf1","category":"page"},{"location":"1_intro/","page":"Theory and Notation","title":"Theory and Notation","text":"boldsymbolbeta_t = mathbfA_t+1 textdiag(mathbfy_t+1)  boldsymbolbeta_t+1\n  textfor   t = N_t-1dots1","category":"page"},{"location":"1_intro/","page":"Theory and Notation","title":"Theory and Notation","text":"where boldsymbolbeta_t is a N_s-long vector containing the  backward probabilities at time t.  Finally the optimization problem can be written as:","category":"page"},{"location":"1_intro/","page":"Theory and Notation","title":"Theory and Notation","text":"textminimize_mathcalL \n \n-log( p (mathbfX) ) = -log(boldsymbolalpha_t^intercal boldsymbolbeta_t )\n\n textst  mathbfY = B_mathcalW(mathbfX)","category":"page"},{"location":"1_intro/","page":"Theory and Notation","title":"Theory and Notation","text":"The classic way of solving this problem is Baum-Weltch, however this approach is has the limitation that B_mathcalW must satisfy certain properties [1]. Another approach which enables the use of  deep neural networks is the gradient descent and all the other  gradient based methods. These methods requires the derivatives  with respect to mathbfa, mathbfA and mathbfY with the latter which is used to backpropagate through B_mathcalW. As we will see the derivatives can be expressed  in terms of posterior probabilities,  i.e. the probability of being at state j given an observation at time t:","category":"page"},{"location":"1_intro/","page":"Theory and Notation","title":"Theory and Notation","text":"gamma_tj = p(s_t=jmathbfx_t) = fracalpha_tj beta_tjp(mathbfX)","category":"page"},{"location":"1_intro/","page":"Theory and Notation","title":"Theory and Notation","text":"Unfortunately forward probabilities suffer of underflow as N_t  increases. To prevent this issue two techniques can be used:  either boldsymbolalpha_t can be scaled at each time step t  or the computation can be performed in the log domain. ","category":"page"},{"location":"1_intro/#Scaled-probabilities","page":"Theory and Notation","title":"Scaled probabilities","text":"","category":"section"},{"location":"1_intro/","page":"Theory and Notation","title":"Theory and Notation","text":"In order to keep boldsymbolalpha_t in a good numerical range, forward probabilities can be normalized at every time step [2-3]:","category":"page"},{"location":"1_intro/","page":"Theory and Notation","title":"Theory and Notation","text":"baralpha_tj = prod_tau = 1^t frac1c_tau alpha_tj ","category":"page"},{"location":"1_intro/","page":"Theory and Notation","title":"Theory and Notation","text":"where c_t is a normalization coefficient  that ensures that sum_j=1^N_s baralpha_tj = 1. This normalization coefficients are then used in the backward computation as well in order to satisfy:","category":"page"},{"location":"1_intro/","page":"Theory and Notation","title":"Theory and Notation","text":"barbeta_tj = prod_tau = t+1^N_t frac1c_tau beta_tj","category":"page"},{"location":"1_intro/","page":"Theory and Notation","title":"Theory and Notation","text":"It turns out the normalization coefficients can be used to  compute p(mathbfX) since at boldsymbolbeta_N_t = mathbf1 then ","category":"page"},{"location":"1_intro/","page":"Theory and Notation","title":"Theory and Notation","text":"p(mathbfX) = sum_j=1^N_s alpha_N_tj =  prod_tau = 1^t c_tau sum_j=1^N_s baralpha_tj","category":"page"},{"location":"1_intro/","page":"Theory and Notation","title":"Theory and Notation","text":"p(mathbfX) = prod_tau = 1^N_t c_tau","category":"page"},{"location":"1_intro/","page":"Theory and Notation","title":"Theory and Notation","text":"and hence the ML cost function can be written as:","category":"page"},{"location":"1_intro/","page":"Theory and Notation","title":"Theory and Notation","text":"log(p(mathbfX)) = sum_tau = 1^N_t log c_tau","category":"page"},{"location":"1_intro/","page":"Theory and Notation","title":"Theory and Notation","text":"Moreover this implies that the posterior probabilities  can be written as:","category":"page"},{"location":"1_intro/","page":"Theory and Notation","title":"Theory and Notation","text":"gamma_tj = \nfracalpha_tj beta_tjp(mathbfX) =\nbaralpha_tj barbeta_tj","category":"page"},{"location":"1_intro/","page":"Theory and Notation","title":"Theory and Notation","text":"The following gradients can be derived:","category":"page"},{"location":"1_intro/","page":"Theory and Notation","title":"Theory and Notation","text":"fracpartial log (p(mathbfX))partial mathbfa  = \n frac1c_1 odot textdiag( mathbfy_1 ) barboldsymbolbeta_1","category":"page"},{"location":"1_intro/","page":"Theory and Notation","title":"Theory and Notation","text":"fracpartial log (p(mathbfX))partial mathbfA  = \nsum_t=1^N_t-1   \nbarboldsymbolalpha_t \n( \nfrac1c_t+1 odot\ntextdiag( mathbfy_t+1 ) \nbarboldsymbolbeta_t+1 \n)^intercal","category":"page"},{"location":"1_intro/","page":"Theory and Notation","title":"Theory and Notation","text":"fracpartial log (p(mathbfX))partial mathbfy_1  = \nfrac1c_1 odot textdiag(mathbfa) barboldsymbolbeta_1","category":"page"},{"location":"1_intro/","page":"Theory and Notation","title":"Theory and Notation","text":"fracpartial log (p(mathbfX))partial mathbfy_t  = \nfrac1c_t odot \ntextdiag(mathbfA^intercalboldsymbolalpha_t-1) barboldsymbolbeta_t\n  textfor   t = 2dotsN_t","category":"page"},{"location":"1_intro/","page":"Theory and Notation","title":"Theory and Notation","text":"where odot is the element wise product (Hadamard product). These can also be expressed more compactly as:","category":"page"},{"location":"1_intro/","page":"Theory and Notation","title":"Theory and Notation","text":"fracpartial log (p(mathbfX))partial mathbfa  = \ntextdiag(mathbfa)^-1 boldsymbolgamma_1 ","category":"page"},{"location":"1_intro/","page":"Theory and Notation","title":"Theory and Notation","text":"fracpartial log (p(mathbfX))partial mathbfA  = \nsum_t=1^N_t-1   \nbarboldsymbolalpha_t \n( \nmathbfA_t^-1\nbarboldsymbolbeta_t \n)^intercal","category":"page"},{"location":"1_intro/","page":"Theory and Notation","title":"Theory and Notation","text":"fracpartial log (p(mathbfX))partial mathbfy_t  = \ntextdiag(mathbfy_t)^-1 boldsymbolgamma_t \n  textfor   t = 1dotsN_t","category":"page"},{"location":"1_intro/","page":"Theory and Notation","title":"Theory and Notation","text":"Notice that in terms of implementation the  former formulas are preferred as  the latter formulas are however valid only for the case where  all the elements of mathbfa and mathbfY are not equal to zero and mathbfA_t is invertible.","category":"page"},{"location":"1_intro/#Log-probabilities","page":"Theory and Notation","title":"Log probabilities","text":"","category":"section"},{"location":"1_intro/","page":"Theory and Notation","title":"Theory and Notation","text":"Another approach to prevent numerical overflown is to compute the forward and backward probabilities in the log-domain.","category":"page"},{"location":"1_intro/","page":"Theory and Notation","title":"Theory and Notation","text":"hatalpha_1j = hata_j + haty_1j\n  textfor   j =1dotsN_s","category":"page"},{"location":"1_intro/","page":"Theory and Notation","title":"Theory and Notation","text":"hatalpha_tj = bigoplus_i in mathcalN_tj \nhatalpha_t-1i +hata_ij + haty_tj\n  textfor   t = 2dotsN_t   j=1dotsN_s","category":"page"},{"location":"1_intro/","page":"Theory and Notation","title":"Theory and Notation","text":"where the hat symbol indicates the variable is in the log-domain, e.g. hatalpha_ij = log(alpha_tj), and oplus(xy) = log(e^x+e^y). Similarly the backward log-probabilities read:","category":"page"},{"location":"1_intro/","page":"Theory and Notation","title":"Theory and Notation","text":"hatbeta_N_tj = 0\n  textfor    j =1dotsN_s","category":"page"},{"location":"1_intro/","page":"Theory and Notation","title":"Theory and Notation","text":"hatbeta_tj = bigoplus_k in barmathcalN_t+1j \nhatbeta_t+1k +\nhata_jk + haty_t+1k\n  textfor   t = N_t-1dots1","category":"page"},{"location":"1_intro/","page":"Theory and Notation","title":"Theory and Notation","text":"The following gradients can be derived:","category":"page"},{"location":"1_intro/","page":"Theory and Notation","title":"Theory and Notation","text":"fracpartial log (p(mathbfX))partial hatmathbfa  = \nboldsymbolgamma_1","category":"page"},{"location":"1_intro/","page":"Theory and Notation","title":"Theory and Notation","text":"fracpartial log (p(mathbfX))partial hatmathbfA  = \nfrac1p(mathbfX)sum_t=1^N_t-1\ne^\nhatalpha_ti + hata_ij + hatbeta_t+1i + haty_t+1j \n\n  textfor   i j = 1dotsN_s ","category":"page"},{"location":"1_intro/","page":"Theory and Notation","title":"Theory and Notation","text":"fracpartial log (p(mathbfX))partial hatmathbfy_t  = \nboldsymbolgamma_t \n  textfor   t = 1dotsN_t","category":"page"},{"location":"1_intro/#references","page":"Theory and Notation","title":"References","text":"","category":"section"},{"location":"1_intro/","page":"Theory and Notation","title":"Theory and Notation","text":"[1] L. A. Liporace, Maximum Likelihood Estimation for Multivariate Observations of Markov Sources, IEEE Trans. Inf. Theory, 1982. \n[2] S. E. Levinson, L. R. Rabiner, M. M. Sondhi, An introduction to the application of the theory of probabilistic functions of a Markov process to automatic speech recognition, Bell System Technical Journal, 1983.\n[3] P. A. Devijver, Baum’s forward-backward algorithm revisited, Pattern Recognition Letters, 1985.","category":"page"},{"location":"#HMMGradients.jl","page":"Home","title":"HMMGradients.jl","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"This package enables computing the gradient of the parameters of Hidden Markov Models (HMMs).  This makes it possible to perform HMM training using gradient based methods like stochastic gradient descent, which is necessary for example when neural networks are involved, e.g. in modern automatic speech recognition systems.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Formally, this package extends ChainRulesCore making it possible to train HMM models using the automatic differentiation frameworks of Julia, for example using Zygote and machine learning libraries like Flux.  The package also provides numerical stable algorithms to compute forward, backward and posterior probabilities of HMMs.","category":"page"},{"location":"#Installation","page":"Home","title":"Installation","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"To install the package, simply issue the following command in the Julia REPL:","category":"page"},{"location":"","page":"Home","title":"Home","text":"] add HMMGradients","category":"page"},{"location":"#Acknowledgements","page":"Home","title":"Acknowledgements","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"This work was developed under  the supsrvision of Prof. Dr. Hervé Bourlard and supported by the Swiss National Science Foundation under the project  \"Sparse and hierarchical Structures for Speech Modeling\" (SHISSM) (no. 200021.175589).","category":"page"},{"location":"2_fb/#Forward-Backward-functions","page":"Forward-Backward functions","title":"Forward-Backward functions","text":"","category":"section"},{"location":"2_fb/#Scaled-probabilities","page":"Forward-Backward functions","title":"Scaled probabilities","text":"","category":"section"},{"location":"2_fb/","page":"Forward-Backward functions","title":"Forward-Backward functions","text":"forward\nforward!\nbackward\nbackward!\nposterior","category":"page"},{"location":"2_fb/#HMMGradients.forward","page":"Forward-Backward functions","title":"HMMGradients.forward","text":"alpha, c = forward(Nt,a,A,y)\n\nComputes the scaled forward probabilities (baralpha) of an Hidden Markov Model (HMM) of Ns states with transition matrix A (must be a Ns × Ns matrix), initial probabilities a (must be a Ns-long vector) and observation likelihoods y (must be of size Nt2 × Ns with Nt2 ≥ Nt).\n\nReturns:\n\nalpha a matrix of size (Nt,Ns) containing the forward probabilities\nc a Nt-long vector containing the normalization coefficients which can be used to compute the backward probabilities (see backward) and the log maximum likelihood (sum(log.(c))).\n\nalpha, c = forward(Nt,t2tr,A,y)\n\nHere t2tr can be an Nt-1 vector of Pair{Vector{D},Vector{D}}. For example given Nt=3:\n\nt2tr = [[1,1]=>[1,2],[1,2]=>[3,3],[3]=>[4]]\n\nindicates that at time t=1 transitions from state 1 to 1 and from 1 to 2 are allowed.  At time t=2 transitions from state 1 to 3 and from 2 to 3 are allowed. At time t=3 only the transition from state 3 to 4 is allowed. In practice these indices can be used to construct the (possibly sparse) time-dependent transition matrices described in the theory section.\n\n\n\n\n\n","category":"function"},{"location":"2_fb/#HMMGradients.forward!","page":"Forward-Backward functions","title":"HMMGradients.forward!","text":"forward!(alpha,c,Nt,a,A,y)\n\nIn-place version of forward.\n\n\n\n\n\n","category":"function"},{"location":"2_fb/#HMMGradients.backward","page":"Forward-Backward functions","title":"HMMGradients.backward","text":"backward(Nt,A,c,y)\n\nComputes the scaled backward probabilities (barbeta) of an Hidden Markov Model (HMM) of Ns states with transition matrix A (must be a Ns × Ns matrix), scale coefficients c (must be a Nt-long vector which is produced by forward) and observation likelihoods y (must be of size Nt2 × Ns with Nt2 ≥ Nt).\n\n\n\n\n\nbackward(Nt,A,c,t2tr,y)\n\nComputes the scaled backward probabilities with constrained path indicated by the t2tr vector. See forward for a description of the structure and meaning of t2tr.\n\n\n\n\n\n","category":"function"},{"location":"2_fb/#HMMGradients.backward!","page":"Forward-Backward functions","title":"HMMGradients.backward!","text":"backward!(beta,Nt,A,c,y)\n\nIn-place version of backward.\n\n\n\n\n\nbackward!(beta,Nt,A,c,t2tr,y)\n\nIn-place version backward with constrined path.\n\n\n\n\n\n","category":"function"},{"location":"2_fb/#HMMGradients.posterior","page":"Forward-Backward functions","title":"HMMGradients.posterior","text":"posterior(Nt,a,A,y)\n\nComputes the state posterior probabilities (gamma) for an HMM model with initial probability a, transition probability matrix A  and observation likelihoods y.\n\n\n\n\n\nposterior(Nt,t2tr,A,y)\n\nComputes the state posterior probabilities (gamma) for an HMM model with constrained path t2tr (see forward), transition probability matrix A  and observation likelihoods y.\n\n\n\n\n\n","category":"function"},{"location":"2_fb/#Log-probabilities","page":"Forward-Backward functions","title":"Log-probabilities","text":"","category":"section"},{"location":"2_fb/","page":"Forward-Backward functions","title":"Forward-Backward functions","text":"logforward\nlogforward!\nlogbackward\nlogbackward!\nlogposterior","category":"page"},{"location":"2_fb/#HMMGradients.logforward","page":"Forward-Backward functions","title":"HMMGradients.logforward","text":"logalpha, logML = logforward(Nt,a,A,y)\n\nComputes the scaled forward log-probabilities (hatalpha) of an Hidden Markov Model (HMM) of Ns states with log-transition matrix A (must be a Ns × Ns matrix), initial log-probabilities a (must be a Ns-long vector) and observation log-likelihoods y (must be of size Nt2 × Ns with Nt2 ≥ Nt).\n\nReturns:\n\nlogalpha a matrix of size (Nt,Ns) containing the forward log-probabilities\nlogML the log likelihood of the observation normalized by the sequence length, i.e. log(P(mathbfX))N_t. \n\nlogalpha, logML = logforward(Nt,t2tr,A,y)\n\nReturns the forward log-probabilities with a constrained path (see forward).\n\n\n\n\n\n","category":"function"},{"location":"2_fb/#HMMGradients.logforward!","page":"Forward-Backward functions","title":"HMMGradients.logforward!","text":"logforward!(logalpha,Nt,a,A,y)\n\nIn-place version of logforward.\n\n\n\n\n\n","category":"function"},{"location":"2_fb/#HMMGradients.logbackward","page":"Forward-Backward functions","title":"HMMGradients.logbackward","text":"logbackward(Nt,A,y)\n\nComputes the backward log-probabilities (hatbeta) of an Hidden Markov Model (HMM) of Ns states with log-transition matrix A (must be a Ns × Ns matrix), scale coefficients and observation log-likelihoods y (must be of size Nt2 × Ns with Nt2 ≥ Nt).\n\n\n\n\n\nlogbackward(Nt,A,t2tr,y)\n\nComputes the backward log-probabilities with constrained path indicated by the t2tr vector. See forward for a description of the structure and meaning of t2tr.\n\n\n\n\n\n","category":"function"},{"location":"2_fb/#HMMGradients.logbackward!","page":"Forward-Backward functions","title":"HMMGradients.logbackward!","text":"logbackward!(logbeta,Nt,A,y)\n\nIn-place version of logbackward.\n\n\n\n\n\n","category":"function"},{"location":"2_fb/#HMMGradients.logposterior","page":"Forward-Backward functions","title":"HMMGradients.logposterior","text":"logposterior(Nt,a,A,y)\n\nComputes the state posterior log-probabilities (hatgamma) for an HMM model with initial probability a, transition probability matrix A  and observation likelihoods y.\n\n\n\n\n\nlogposterior(Nt,t2tr,A,y)\n\nComputes the state posterior log-probabilities (hatgamma) for an HMM model with constrained path t2tr (see forward), transition probability matrix A  and observation likelihoods y.\n\n\n\n\n\n","category":"function"},{"location":"3_grads/#Computing-gradients","page":"Computing gradients","title":"Computing gradients","text":"","category":"section"},{"location":"3_grads/","page":"Computing gradients","title":"Computing gradients","text":"This package uses ChainRulesCore.jl API extending its rrule function.  Specifically the following cost functions can be differentiated. ","category":"page"},{"location":"3_grads/","page":"Computing gradients","title":"Computing gradients","text":"nlogML\nnlogMLlog","category":"page"},{"location":"3_grads/#HMMGradients.nlogML","page":"Computing gradients","title":"HMMGradients.nlogML","text":"nlogML(Nt,a,A,y)\n\nComputes the negative log Maximum Likelihood (ML) normalized by the sequence length (log(P(mathbfX))N_t) of a Hidden Markov Model (HMM) with Ns states, transition matrix A (a Ns × Ns matrix), initial probabilities a (Ns-vector) and observation probabilities y (a Ns×Nt matrix) for Nt observations. All Arrays must have the same element type.\n\nnlogML(Nt,t2tr,A,y)\n\nReturns the negative log Maximum Likelihood (ML) normalized by the sequence length (log(P(mathbfX))N_t) with a constrained path (see forward).\n\n\n\n\n\n","category":"function"},{"location":"3_grads/#HMMGradients.nlogMLlog","page":"Computing gradients","title":"HMMGradients.nlogMLlog","text":"nlogMLlog(Nt,A,a,y)\n\nSame as nlogML but expects A, a and y to be in the log-domain.\n\n\n\n\n\n","category":"function"},{"location":"3_grads/","page":"Computing gradients","title":"Computing gradients","text":"For example if we want to get derivatives for the following model:","category":"page"},{"location":"3_grads/","page":"Computing gradients","title":"Computing gradients","text":"julia> using HMMGradients, ChainRulesCore\n\njulia> a = [1.0,0.0];\n\njulia> A = [0.5 0.5; 0.5 0.5];\n\njulia> y = [0.1 0.7; 0.5 0.8; 0.9 0.3];\n\njulia> Ns,Nt = size(A,1), size(y,1);\n\njulia> cost = nlogML(Nt,a,A,y)\n1.0813978776174968","category":"page"},{"location":"3_grads/","page":"Computing gradients","title":"Computing gradients","text":"all we need to do is to use rrule, which will return cost and  the pullback function:","category":"page"},{"location":"3_grads/","page":"Computing gradients","title":"Computing gradients","text":"julia> cost, pullback_nlogML = ChainRulesCore.rrule(nlogML, Nt, a, A, y);\n\njulia> _, _, grada, gradA, grady = pullback_nlogML(1.0);\n\njulia> [println(grad) for grad in [grada,gradA,grady]];\n[-0.3333333333333333, -2.3333333333333335]\n[-0.4487179487179487 -0.4743589743589744; -0.30769230769230776 -0.10256410256410257]\n[-3.3333333333333335 -0.0; -0.2564102564102564 -0.2564102564102564; -0.2777777777777778 -0.2777777777777778]\n","category":"page"},{"location":"3_grads/","page":"Computing gradients","title":"Computing gradients","text":"When we need to impose only specific paths to be allowed through the HMM only the gradient with respect to y is computed.","category":"page"},{"location":"3_grads/","page":"Computing gradients","title":"Computing gradients","text":"julia> t2tr = [[1,1]=>[1,2],[1,2]=>[2,2]];\n\njulia> cost, pullback_nlogML = ChainRulesCore.rrule(nlogML, Nt, t2tr, A, y);\n\njulia> _, _, grada, gradA, grady = pullback_nlogML(1.0);\n\njulia> @assert grada == gradA == ChainRulesCore.DoesNotExist();\n\njulia> grady\n3×2 Array{Float64,2}:\n -3.33333  -0.0\n -0.25641  -0.25641\n -0.0      -1.11111\n","category":"page"},{"location":"3_grads/","page":"Computing gradients","title":"Computing gradients","text":"It is also possible to perform these operations in batches. Say we have Nb sequences of different length then size(yb) == (Nt_max,Ns,Nb) where Nt_max is the maximum of length sequence. For example:","category":"page"},{"location":"3_grads/","page":"Computing gradients","title":"Computing gradients","text":"julia> Nb = 2; # number of sequences\n\njulia> Nts = [3,4]; # sequences length\n\njulia> ys = [[0.1 0.7; 0.5 0.8; 0.9 0.3], [0.5 0.3; 0.7 0.7; 0.1 0.1; 0.5 0.0]];\n\njulia> Nt_max = maximum(size.(ys,1)); # calculate maximum seq length\n\njulia> yb = zeros(Nt_max,Ns,Nb); \n\njulia> for b in 1:Nb yb[1:Nts[b],:,b] .= ys[b] end; # yb has zeropadded inputs\n\njulia> t2trs = [ [[1,1]=>[1,2],[1,2]=>[2,2]], [[2]=>[2],[2]=>[2],[2]=>[1]] ];\n\njulia> @assert all(length.(t2trs) .== Nts .-1);\n\njulia> cost, pullback_nlogML = ChainRulesCore.rrule(nlogML, Nts, t2trs, A, yb);\n\njulia> _, _, _, _, grady = pullback_nlogML(1.0);\n\njulia> grady\n4×2×2 Array{Float64,3}:\n[:, :, 1] =\n -3.33333  -0.0\n -0.25641  -0.25641\n -0.0      -1.11111\n -0.0      -0.0\n\n[:, :, 2] =\n -0.0  -0.833333\n -0.0  -0.357143\n -0.0  -2.5\n -0.5  -0.0","category":"page"},{"location":"3_grads/","page":"Computing gradients","title":"Computing gradients","text":"Batch computation is also available for the unconstrained case. In this case a and A must be of the of size (Ns,Nb) and (Ns,Ns,Nb) respectively. The same computations can be performed in the log domain using nlogMLlog  after applying log to a, A and y.","category":"page"}]
}
